{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import argparse\n",
    "import h5py\n",
    "from torch.autograd import Variable\n",
    "from model import NetD, NetG\n",
    "from PIL import Image, ImageDraw\n",
    "import torchvision.transforms as transforms\n",
    "from misc import get_logger, ges_Aonfig\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse_metadata import EcommerceDataParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_image(images,nrows, ncols):\n",
    "    width = 128\n",
    "    height = 128\n",
    "    \n",
    "    background = Image.new('RGB',(128*ncols, 128*nrows), (255, 255, 255, 255))\n",
    "    bg_w, bg_h = background.size\n",
    "    \n",
    "    for i,image in enumerate(images):\n",
    "    #print(i)\n",
    "        img = image\n",
    "        draw = ImageDraw.Draw(img, \"RGB\")\n",
    "        #font = ImageFont.truetype(\"/Library/Fonts/Arial.ttf\",50)\n",
    "        #draw.text((50, 50), str(i),)\n",
    "        start_X = i%ncols * 128\n",
    "        start_Y = i//ncols * 128\n",
    "        offset = (start_X,start_Y,start_X+width,start_Y+height)\n",
    "        background.paste(img,offset)\n",
    "        \n",
    "    return background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_checkpoint_path = 'outputs/g_netD__epoch_995.pth'\n",
    "g_checkpoint_path = 'outputs/netg_checkpoints_0-995/netG__epoch_995.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_z = 100\n",
    "n_l = 100\n",
    "n_t = 300\n",
    "n_c = 64\n",
    "netG = NetG(n_z=n_z, n_l=n_l, n_c=n_c, n_t=n_t)\n",
    "netD = NetD(n_cls=10, n_t=100, n_f=64,docvec_size=300)\n",
    "netD.load_state_dict(torch.load(d_checkpoint_path, map_location=lambda storage, loc: storage))\n",
    "netG.load_state_dict(torch.load(g_checkpoint_path, map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToPILImage(),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG.zero_grad()\n",
    "netD.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ges_Aonfig('configs/config-real.yaml')['PARSEMETA']\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['SPM_DIR_PATH'] = 'data/g_spm'\n",
    "config['SPM_WP_PATH'] = 'data/g_spm/spm.vocab'\n",
    "config['PARSE_DATA_PATH'] = 'data/datasets/products/g_products.tsv'\n",
    "config['DOC2VEC_DIR_PATH'] = 'data/g_doc2vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = EcommerceDataParser(config, use=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/datasets/products/g_products.tsv',sep='\\t',header=None)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = parser.text2wp('yamaha classical nylon string guitars yamaha c40 full size nylon string classical guitar')\n",
    "parser.query_doc2vec_topn(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[1,2]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    while True:\n",
    "        title= input('1. 상품명을 입력해주세요!:\\t') #'solid body schecter electric guitar'\n",
    "        category= input('2. 카테고리명을 입력해주세요!:\\t') #'electric guitars'\n",
    "        brand= input('3. 브랜드명을 입력해주세요!:\\t') #'yamaha'\n",
    "        attr = input('4. 색상을 입력해주세요!:\\t') #'sea blue'\n",
    "        text = ' '.join([category, brand, attr, title])\n",
    "        print('\\n [title]: ',text)\n",
    "\n",
    "        vec = parser.text2vec(text)\n",
    "        caption = Variable(torch.from_numpy(vec.reshape(1,-1)))\n",
    "        noise = Variable(torch.randn(1, 100)) # create random noise\n",
    "        noise.data.normal_(0,1) # normalize the noise\n",
    "        fake = netG(noise, caption)\n",
    "        img = transform(fake[0].data)\n",
    "        plt.figure()\n",
    "        plt.imshow(img)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### abuse checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_to_numpy(obj, isReal=True):\n",
    "    obj = obj.permute(0,2,3,1)\n",
    "\n",
    "    if isReal:\n",
    "        obj = (obj+1) / 2\n",
    "    else:\n",
    "        obj = obj.squeeze(3)\n",
    "    obj = torch.clamp(obj, min=0, max=1)\n",
    "    return obj.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_img = transforms.Compose([transforms.Resize((128, 128)), #transforms.CenterCrop(image_size),\n",
    "                                             transforms.ToTensor(),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "images = []\n",
    "real_images = []\n",
    "imgdir = 'data/datasets/products/images'\n",
    "temp_df = []\n",
    "for index in range(n,n+10):\n",
    "    asin = df[0][index] + '.jpg'\n",
    "    title = df[2][index]\n",
    "    real_images.append(Image.open(os.path.join(imgdir,asin)).resize((128,128)))\n",
    "    img = Variable(trans_img(real_images[-1]).view(-1,3,128,128))\n",
    "    vec = parser.text2vec(title)\n",
    "    caption = Variable(torch.from_numpy(vec.reshape(1,-1)))\n",
    "    noise = Variable(torch.randn(1, 100)) # create random noise\n",
    "    noise.data.normal_(0,1) # normalize the noise\n",
    "    fake = netG(noise, caption)\n",
    "    \n",
    "    isreal, isclass = netD(img,caption)\n",
    "    result = isreal.data.numpy()#, isclass.data.numpy()\n",
    "    print(result)\n",
    "    temp_df.append(df.loc[[index]])\n",
    "pd.concat(temp_df)[[1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_image(real_images,1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1070 1: 95s\n",
    "# parallel 1: 0.61 min 36s (batchsize=128, load=90~), 0.73 min  43s (batchsize=32, load=85~90)\n",
    "# parallel 2: 0.56 min 33s (batchsize=64, load=80~90)\n",
    "# parallel 3: 0.46 min 27s (batchsize=96, load=60~70)\n",
    "# parallel 4: 0.43 min 25s (batchsize=128, load=40~50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams[\"figure.figsize\"] = (20,4)\n",
    "# x = ['gtx 1070', \n",
    "#      'dgx single (batch=128)', \n",
    "#      'dgx single (batch=32)', \n",
    "#      'dgx multi-2 (batch=64)', \n",
    "#      'dgx multi-3 (batch=96)', \n",
    "#      'dgx multi-4 (batch=128)']\n",
    "\n",
    "# energy = [95,  36, 43, 33, 27, 25]\n",
    "\n",
    "# x_pos = [i for i, _ in enumerate(x)]\n",
    "# print(x_pos)\n",
    "# plt.barh(x_pos, energy, color='green')\n",
    "# plt.ylabel(\"GPU models\",size=15)\n",
    "# plt.xlabel(\"Sec per Epoch\",size=15)\n",
    "# plt.title(\"Performance by gpu model\",size=20)\n",
    "\n",
    "# plt.yticks(x_pos, x)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.0 on Python 3.6 (CUDA 10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
