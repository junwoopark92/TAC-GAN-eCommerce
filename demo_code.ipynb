{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import argparse\n",
    "import h5py\n",
    "from torch.autograd import Variable\n",
    "from model import NetD, NetG\n",
    "from PIL import Image, ImageDraw\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat_image(images,nrows, ncols):\n",
    "    width = 128\n",
    "    height = 128\n",
    "    \n",
    "    background = Image.new('RGBA',(128*ncols, 128*nrows), (255, 255, 255, 255))\n",
    "    bg_w, bg_h = background.size\n",
    "    \n",
    "    for i,image in enumerate(images):\n",
    "    #print(i)\n",
    "        img = image\n",
    "        draw = ImageDraw.Draw(img, \"RGB\")\n",
    "        #font = ImageFont.truetype(\"/Library/Fonts/Arial.ttf\",50)\n",
    "        #draw.text((50, 50), str(i),)\n",
    "        start_X = i%ncols * 128\n",
    "        start_Y = i//ncols * 128\n",
    "        offset = (start_X,start_Y,start_X+width,start_Y+height)\n",
    "        background.paste(img,offset)\n",
    "        \n",
    "    return background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = h5py.File('./data/datasets/products/train/data.h5py','r')['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in h.keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h['asin'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h['cate'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint_path = 'outputs/netg_checkpoints/netG__epoch_45.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_z = 100\n",
    "n_l = 100\n",
    "n_t = 500\n",
    "n_c = 64\n",
    "netG = NetG(n_z=n_z, n_l=n_l, n_c=n_c, n_t=n_t)\n",
    "netG.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToPILImage(),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netG.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = 3\n",
    "caption = Variable(torch.from_numpy(h['docvec'][index].reshape(1,-1)))\n",
    "noise = Variable(torch.randn(1, 100)) # create random noise\n",
    "noise.data.normal_(0,1) # normalize the noise\n",
    "fake = netG(noise, caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = transform(fake[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### val sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 173658 entries, 0 to 173657\n",
      "Data columns (total 4 columns):\n",
      "0    173658 non-null object\n",
      "1    173658 non-null object\n",
      "2    173658 non-null object\n",
      "3    173658 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/datasets/products/products.tsv',sep='\\t',header=None)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clothing,Shoes&Jewelry>Women>Clothing>Coats&Jackets                   17993\n",
       "Clothing,Shoes&Jewelry>Girls>Clothing>Dresses                         16716\n",
       "Clothing,Shoes&Jewelry>Women>Shoes>Boots                              15660\n",
       "Beauty>Makeup>Lips>Lipstick                                           14499\n",
       "Clothing,Shoes&Jewelry>Women>Accessories>Hats&Caps                    13838\n",
       "Clothing,Shoes&Jewelry>N>Nike                                         13811\n",
       "Clothing,Shoes&Jewelry>Women>Handbags&Wallets>ShoulderBags            13737\n",
       "Tools&HomeImprovement>Lighting&CeilingFans>Lamps&Shades>TableLamps    11430\n",
       "Clothing,Shoes&Jewelry>Women>Clothing>Skirts                          11428\n",
       "Automotive>Motorcycle&Powersports>ProtectiveGear>Helmets              10866\n",
       "Clothing,Shoes&Jewelry>adidas                                          9923\n",
       "Home&Kitchen>Furniture>LivingRoomFurniture>Tables                      9203\n",
       "MusicalInstruments>Guitars>ElectricGuitars>SolidBody                   5583\n",
       "MusicalInstruments>Guitars>Acoustic-ElectricGuitars                    3020\n",
       "MusicalInstruments>Guitars>AcousticGuitars>Steel-stringAcoustics       2021\n",
       "MusicalInstruments>BassGuitars>ElectricBasses                          1414\n",
       "MusicalInstruments>Guitars>Classical&Nylon-StringGuitars                939\n",
       "MusicalInstruments>Guitars>ElectricGuitars>Hollow&Semi-HollowBody       568\n",
       "MusicalInstruments>Guitars>AcousticGuitars>Resonators                   381\n",
       "MusicalInstruments>Guitars>AcousticGuitars                              233\n",
       "MusicalInstruments>Guitars>ElectricGuitars                              225\n",
       "MusicalInstruments>BassGuitars>Acoustic&Acoustic-ElectricBasses         170\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = df[df[1] == 'Movies&TV>Movies']\n",
    "imgdir = 'data/datasets/products/images/'\n",
    "images = []\n",
    "for i, row in sub.iterrows():\n",
    "    asin = row[0]\n",
    "    images.append(Image.open( imgdir+ asin +'.jpg').resize((128,128)))\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "concat_image(images,1,len(images))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
